{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Operations.CO_CompareMinAMI import CO_CompareMinAMI\n",
    "from Operations.CO_AutoCorrShape import CO_AutoCorrShape\n",
    "from Operations.CO_TranslateShape import CO_TranslateShape\n",
    "from Operations.CP_wavelet_varch import CP_wavelet_varchg\n",
    "from Operations.EN_SampEn import EN_SampEn\n",
    "from Operations.EN_wentropy import EN_wentropy\n",
    "from Operations.CO_AddNoise import CO_AddNoise\n",
    "from Operations.CO_AutoCorr import CO_AutoCorr\n",
    "from PeripheryFunctions.BF_iszscored import BF_iszscored\n",
    "from Operations.DT_IsSeasonal import DT_IsSeasonal\n",
    "from PeripheryFunctions.BF_Embed import BF_Embed\n",
    "from Operations.EN_rpde import EN_rpde\n",
    "from Operations.SC_FluctAnal import SC_FluctAnal\n",
    "from Operations.CO_CompareMinAMI import CO_CompareMinAMI\n",
    "from Operations.PH_ForcePotential import PH_ForcePotential\n",
    "from PeripheryFunctions.BF_zscore import BF_zscore\n",
    "from PeripheryFunctions.BF_SimpleBinner import BF_SimpleBinner\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from loguru import logger\n",
    "from Utils import wrcoef\n",
    "from scipy.interpolate import make_lsq_spline, BSpline\n",
    "from Utils.wrcoef import wavedec, wrcoef, detcoef\n",
    "from Operations.WL_coeffs import WL_coeffs\n",
    "import pywt\n",
    "from typing import Union, Optional\n",
    "import numpy.linalg\n",
    "from lmfit.models import GaussianModel, PowerLawModel, ExponentialModel\n",
    "from statsmodels.tsa.ar_model import AutoReg, ar_select_order, AR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts1 = np.loadtxt(\"ts1.txt\")\n",
    "ts2 = np.loadtxt(\"ts2.txt\")\n",
    "ts3 = np.loadtxt(\"ts3.txt\")\n",
    "ts4 = np.loadtxt(\"ts4.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00193995, 0.00295549, 0.00442302, 0.00650255, 0.00939184,\n",
       "       0.01332756, 0.01858304, 0.02546165, 0.0342848 , 0.04537408,\n",
       "       0.05902781, 0.07549287, 0.09493363, 0.11740099, 0.14280473,\n",
       "       0.17089318, 0.20124363, 0.23326654, 0.26622495, 0.299269  ,\n",
       "       0.33148362, 0.36194524, 0.38978253, 0.4142349 , 0.43470273,\n",
       "       0.45078434, 0.46229597, 0.46927332, 0.4719554 , 0.47075333,\n",
       "       0.46620836, 0.45894416, 0.44961864, 0.43887982, 0.42732933,\n",
       "       0.41549575, 0.40381836, 0.39264091, 0.38221389, 0.37270314,\n",
       "       0.36420264, 0.3567493 , 0.3503379 , 0.34493494, 0.34049053,\n",
       "       0.33694795, 0.33425095, 0.3323489 , 0.33120029, 0.33077496,\n",
       "       0.33105539, 0.33203736, 0.33373009, 0.3361559 , 0.33934909,\n",
       "       0.34335395, 0.34822135, 0.35400356, 0.36074694, 0.36848229,\n",
       "       0.37721285, 0.38690031, 0.39744982, 0.40869516, 0.42038603,\n",
       "       0.43217949, 0.44363783, 0.45423501, 0.46337295, 0.47040832,\n",
       "       0.47468902, 0.47559819, 0.47260222, 0.46529811, 0.45345511,\n",
       "       0.43704553, 0.41626048, 0.39150801, 0.36339287, 0.33267936,\n",
       "       0.30024109, 0.26700248, 0.23387827, 0.20171686, 0.17125305,\n",
       "       0.14307368, 0.11759845, 0.09507602, 0.07559368, 0.05909787,\n",
       "       0.04542184, 0.03431674, 0.02548259, 0.01859648, 0.01333601,\n",
       "       0.00939704, 0.00650568, 0.00442486, 0.00295654, 0.00194054])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kde = KernelDensity(bandwidth='silverman', kernel='gaussian').fit(ts1[:, None]) # closest match to the default behaviour of ksdensity in MATLAB\n",
    "lower = ts1.min() - 3 * kde.bandwidth_\n",
    "upper = ts1.max() + 3 * kde.bandwidth_\n",
    "xi = np.linspace(lower, upper, 100)[:,None]\n",
    "f = np.exp(kde.score_samples(xi))\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(6.90993179085722)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-2 * np.log10(10954.481) + 5 * np.log10(995)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>AutoReg Model Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>y</td>        <th>  No. Observations:  </th>    <td>1000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>            <td>AutoReg(5)</td>    <th>  Log Likelihood     </th>  <td>10954.481</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>         <td>Conditional MLE</td> <th>  S.D. of innovations</th>    <td>0.000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Sat, 15 Feb 2025</td> <th>  AIC                </th> <td>-21896.962</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>16:05:37</td>     <th>  BIC                </th> <td>-21867.545</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sample:</th>                <td>5</td>        <th>  HQIC               </th> <td>-21885.779</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                     <td>1000</td>       <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>      <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>y.L1</th> <td>    0.7647</td> <td>    0.030</td> <td>   25.671</td> <td> 0.000</td> <td>    0.706</td> <td>    0.823</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>y.L2</th> <td>    0.4847</td> <td>    0.038</td> <td>   12.792</td> <td> 0.000</td> <td>    0.410</td> <td>    0.559</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>y.L3</th> <td>    0.1460</td> <td>    0.041</td> <td>    3.595</td> <td> 0.000</td> <td>    0.066</td> <td>    0.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>y.L4</th> <td>   -0.1892</td> <td>    0.038</td> <td>   -5.001</td> <td> 0.000</td> <td>   -0.263</td> <td>   -0.115</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>y.L5</th> <td>   -0.3415</td> <td>    0.030</td> <td>  -11.479</td> <td> 0.000</td> <td>   -0.400</td> <td>   -0.283</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<caption>Roots</caption>\n",
       "<tr>\n",
       "    <td></td>   <th>            Real</th>  <th>         Imaginary</th> <th>         Modulus</th>  <th>        Frequency</th>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AR.1</th> <td>           0.9801</td> <td>          -0.1987j</td> <td>           1.0000</td> <td>          -0.0318</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AR.2</th> <td>           0.9801</td> <td>          +0.1987j</td> <td>           1.0000</td> <td>           0.0318</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AR.3</th> <td>          -0.5147</td> <td>          -1.3066j</td> <td>           1.4044</td> <td>          -0.3097</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AR.4</th> <td>          -0.5147</td> <td>          +1.3066j</td> <td>           1.4044</td> <td>           0.3097</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AR.5</th> <td>          -1.4847</td> <td>          -0.0000j</td> <td>           1.4847</td> <td>          -0.5000</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:} &             y             & \\textbf{  No. Observations:  } &            1000            \\\\\n",
       "\\textbf{Model:}         &         AutoReg(5)        & \\textbf{  Log Likelihood     } &         10954.481          \\\\\n",
       "\\textbf{Method:}        &      Conditional MLE      & \\textbf{  S.D. of innovations} &           0.000            \\\\\n",
       "\\textbf{Date:}          &      Sat, 15 Feb 2025     & \\textbf{  AIC                } &         -21896.962         \\\\\n",
       "\\textbf{Time:}          &          16:05:37         & \\textbf{  BIC                } &         -21867.545         \\\\\n",
       "\\textbf{Sample:}        &             5             & \\textbf{  HQIC               } &         -21885.779         \\\\\n",
       "\\textbf{}               &            1000           & \\textbf{                     } &                            \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "              & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{y.L1} &       0.7647  &        0.030     &    25.671  &         0.000        &        0.706    &        0.823     \\\\\n",
       "\\textbf{y.L2} &       0.4847  &        0.038     &    12.792  &         0.000        &        0.410    &        0.559     \\\\\n",
       "\\textbf{y.L3} &       0.1460  &        0.041     &     3.595  &         0.000        &        0.066    &        0.226     \\\\\n",
       "\\textbf{y.L4} &      -0.1892  &        0.038     &    -5.001  &         0.000        &       -0.263    &       -0.115     \\\\\n",
       "\\textbf{y.L5} &      -0.3415  &        0.030     &   -11.479  &         0.000        &       -0.400    &       -0.283     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccc}\n",
       "              & \\textbf{            Real} & \\textbf{         Imaginary} & \\textbf{         Modulus} & \\textbf{        Frequency}  \\\\\n",
       "\\midrule\n",
       "\\textbf{AR.1} &                0.9801     &                -0.1987j     &                1.0000     &               -0.0318       \\\\\n",
       "\\textbf{AR.2} &                0.9801     &                +0.1987j     &                1.0000     &                0.0318       \\\\\n",
       "\\textbf{AR.3} &               -0.5147     &                -1.3066j     &                1.4044     &               -0.3097       \\\\\n",
       "\\textbf{AR.4} &               -0.5147     &                +1.3066j     &                1.4044     &                0.3097       \\\\\n",
       "\\textbf{AR.5} &               -1.4847     &                -0.0000j     &                1.4847     &               -0.5000       \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{AutoReg Model Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            AutoReg Model Results                             \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                 1000\n",
       "Model:                     AutoReg(5)   Log Likelihood               10954.481\n",
       "Method:               Conditional MLE   S.D. of innovations              0.000\n",
       "Date:                Sat, 15 Feb 2025   AIC                         -21896.962\n",
       "Time:                        16:05:37   BIC                         -21867.545\n",
       "Sample:                             5   HQIC                        -21885.779\n",
       "                                 1000                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "y.L1           0.7647      0.030     25.671      0.000       0.706       0.823\n",
       "y.L2           0.4847      0.038     12.792      0.000       0.410       0.559\n",
       "y.L3           0.1460      0.041      3.595      0.000       0.066       0.226\n",
       "y.L4          -0.1892      0.038     -5.001      0.000      -0.263      -0.115\n",
       "y.L5          -0.3415      0.030    -11.479      0.000      -0.400      -0.283\n",
       "                                    Roots                                    \n",
       "=============================================================================\n",
       "                  Real          Imaginary           Modulus         Frequency\n",
       "-----------------------------------------------------------------------------\n",
       "AR.1            0.9801           -0.1987j            1.0000           -0.0318\n",
       "AR.2            0.9801           +0.1987j            1.0000            0.0318\n",
       "AR.3           -0.5147           -1.3066j            1.4044           -0.3097\n",
       "AR.4           -0.5147           +1.3066j            1.4044            0.3097\n",
       "AR.5           -1.4847           -0.0000j            1.4847           -0.5000\n",
       "-----------------------------------------------------------------------------\n",
       "\"\"\""
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod = AutoReg(ts1, lags=5, trend='n')\n",
    "res = mod.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.0500092115061956e-11)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod = AutoReg(ts1, lags=np.arange(1, 11), trend='n')\n",
    "res = mod.fit()\n",
    "res.sigma2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigvals, eigvecs = np.linalg.eig(np.diag(res.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.06004257, -0.07960433, -0.11872864, -0.13083671, -0.12413532,\n",
       "       -0.08097929, -0.06575356,  0.01040791,  0.07933451,  0.17865283,\n",
       "       -0.03238517,  0.01132411, -0.06359846,  0.00245538,  0.04774069,\n",
       "        0.02427306, -0.02749503,  0.02765683, -0.01020147, -0.02863997])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CO_AutoCorr(res.resid, list(np.arange(1, 21)), 'Fourier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.27902981,  0.39968788],\n",
       "       [ 0.20926432,  0.33651149],\n",
       "       [ 0.11079878,  0.24163217],\n",
       "       [ 0.01854654,  0.1510526 ],\n",
       "       [ 0.09347442,  0.22639271],\n",
       "       [-0.05131512,  0.0815639 ],\n",
       "       [-0.11812205,  0.01439032],\n",
       "       [-0.17672288, -0.04595361],\n",
       "       [-0.16130575, -0.03431713],\n",
       "       [-0.30772463, -0.18724772]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.conf_int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(11108.671209667926)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.llf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(-22141.467664961438)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(res.bic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "990"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.nobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arfit(x, pmin, pmax):\n",
    "\n",
    "    N = len(x)\n",
    "\n",
    "    mod = AutoReg(x, lags=np.arange(pmin, pmax+1), trend='n') # no intercept vector (data assumed to be zero-mean, zscored)\n",
    "    mod_fit = mod.fit()\n",
    "    aest = mod_fit.params # AR model coefficients\n",
    "    cest = mod_fit.sigma2 # noise variance\n",
    "\n",
    "    popt = len(aest)\n",
    "\n",
    "    out = {}\n",
    "    out[\"A1\"] = aest[0]\n",
    "    for i in range(1, 6):\n",
    "        if popt >= i:\n",
    "            out[f\"A{i+1}\"] = aest[i]\n",
    "        else:\n",
    "            # if it's as if the higher order coefficients are all zero\n",
    "            out[f\"A{i}\"] = 0\n",
    "\n",
    "    # summary statistics on the coefficients\n",
    "    out[\"maxA\"] = np.max(aest)\n",
    "    out[\"minA\"] = np.min(aest)\n",
    "    out[\"meanA\"] = np.mean(aest)\n",
    "    out[\"stdA\"] = np.std(aest, ddof=1)\n",
    "    out[\"sumA\"] = np.sum(aest)\n",
    "    out[\"rmsA\"] = np.sqrt(np.sum(aest**2))\n",
    "    out[\"sumsqA\"] = np.sum(aest**2)\n",
    "\n",
    "    # noise covariance matrix\n",
    "    out[\"C\"] = cest\n",
    "\n",
    "    # Bayesian Information Criterion (BIC)\n",
    "    \n",
    "\n",
    "    # Aikiake\n",
    "\n",
    "    # Test Resdiuals\n",
    "    residuals = mod_fit.resid\n",
    "    out[\"res_ac1\"] = CO_AutoCorr(residuals, 1, 'Fourier')\n",
    "    out[\"res_ac1_norm\"] = CO_AutoCorr(residuals, 1, 'Fourier')/np.sqrt(N) # normalize by sqrt(N)\n",
    "    # calculate correlations up to 20, return how many exceed significance threshold\n",
    "    acf = CO_AutoCorr(residuals, list(np.arange(1, 21)), 'Fourier') \n",
    "    out['pcorr_res'] = np.sum(np.abs(acf)>1.96/np.sqrt(N))/20\n",
    "\n",
    "    # Confidence intervals\n",
    "    ci95s = res.bse * 1.96 # 95% CI\n",
    "    out[\"aerr_min\"] = np.min(ci95s)\n",
    "    out[\"aerr_max\"] = np.max(ci95s)\n",
    "    out[\"aerr_mean\"] = np.mean(ci95s)\n",
    "\n",
    "    # eigendecomposition\n",
    "    \n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "AutoReg.__init__() got an unexpected keyword argument 'method'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[159], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43marfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mts1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[158], line 5\u001b[0m, in \u001b[0;36marfit\u001b[0;34m(x, pmin, pmax)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21marfit\u001b[39m(x, pmin, pmax):\n\u001b[1;32m      3\u001b[0m     N \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(x)\n\u001b[0;32m----> 5\u001b[0m     mod \u001b[38;5;241m=\u001b[39m \u001b[43mAutoReg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpmax\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcmle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# no intercept vector (data assumed to be zero-mean, zscored)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     mod_fit \u001b[38;5;241m=\u001b[39m mod\u001b[38;5;241m.\u001b[39mfit()\n\u001b[1;32m      7\u001b[0m     aest \u001b[38;5;241m=\u001b[39m mod_fit\u001b[38;5;241m.\u001b[39mparams \u001b[38;5;66;03m# AR model coefficients\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: AutoReg.__init__() got an unexpected keyword argument 'method'"
     ]
    }
   ],
   "source": [
    "arfit(ts1, 1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MF_ExpSmoothing(x, ntrain : Optional[float] = None , alpha : str = 'best'):\n",
    "    N = len(x)\n",
    "    if not ntrain:\n",
    "        ntrain = min(100, N)\n",
    "    if (ntrain > 0) and (ntrain < 1):\n",
    "        ntrain = int(np.floor(N*ntrain))\n",
    "    \n",
    "    out = {}\n",
    "    minTrain = 100\n",
    "    maxTrain = 1000\n",
    "\n",
    "    if ntrain > maxTrain:\n",
    "        print(f\"Training set size reduced from {ntrain} to maximum of 1000 samples.\")\n",
    "        ntrain = 1000\n",
    "    if ntrain < minTrain:\n",
    "        print(f\"Training set size increased from {ntrain} to minimum of 100.\")\n",
    "        ntrain = 100\n",
    "    if N < ntrain:\n",
    "        logger.warning(\"Time Series too short for exponential smoothing\")\n",
    "        return np.nan\n",
    "    \n",
    "    if alpha == 'best':\n",
    "        xtrain = x[:ntrain]\n",
    "        # do a descent\n",
    "        # fits a quadratic to available points\n",
    "        alphar = np.linspace(0.1, 0.9, 5)\n",
    "        rmses = np.zeros(len(alphar))\n",
    "        for (i, a) in enumerate(alphar):\n",
    "            xf = SUB_fit_exp_smooth(xtrain, a)\n",
    "            # issue forecasts\n",
    "            fore = xf[2:]\n",
    "            orig = xtrain[2:]\n",
    "            rmses[i] = np.sqrt(np.mean((fore - orig)**2))\n",
    "\n",
    "        # fit quadratic to set alpha\n",
    "        ix = np.argsort(rmses)\n",
    "        rkeep = ix[:3]\n",
    "        p = np.polyfit(alphar[rkeep], rmses[rkeep], 2)\n",
    "        aar = np.arange(0, 1.005, 0.005)\n",
    "        y = np.polyval(p, aar)\n",
    "        alphamin = -p[1]/(2*p[0])\n",
    "        out['alphamin_1'] = alphamin\n",
    "        out['p1_1'] = np.abs(p[0]) # concavity\n",
    "        out['cup_1'] = np.sign(p[0])\n",
    "\n",
    "        if p[0] < 0:  # concave down -- it's looking at a minimum\n",
    "            if y[0] < y[-1]:\n",
    "                alphamin = 0.01\n",
    "            else:\n",
    "                alphamin = 1\n",
    "        else:\n",
    "            #% Search again around this\n",
    "            alphar = np.linspace(alphamin-0.1, alphamin+0.1, 5)\n",
    "            if np.any(alphar <= 0):\n",
    "                alphar = np.linspace(0.1, max(alphamin, 0)+0.1, 5)\n",
    "            elif any(alphar >= 1):\n",
    "                alphar = np.linspace(min(alphamin, 1)-0.1, 1, 5)\n",
    "            \n",
    "            for k in range(len(alphar)):\n",
    "                a = alphar[k]\n",
    "                xf = SUB_fit_exp_smooth(xtrain, a)\n",
    "                fore = xf[2:]\n",
    "                orig = xtrain[2:]\n",
    "                rmses[k] = np.sqrt(np.mean((fore - orig)**2))\n",
    "            \n",
    "            p = np.polyfit(alphar, rmses, 2)\n",
    "\n",
    "            if p[0] < 0:\n",
    "                alphamin = alphar[np.argmin(rmses)]\n",
    "            else:\n",
    "                alphamin = -p[1]/(2*p[0])\n",
    "                if alphamin > 1:\n",
    "                    alphamin = 1\n",
    "                elif alphamin <= 0:\n",
    "                    alphamin = 0.01\n",
    "        \n",
    "    out['alphamin'] = alphamin\n",
    "    alpha = alphamin\n",
    "\n",
    "    #(2) Fit to the whole time series\n",
    "    y = SUB_fit_exp_smooth(x, alpha)\n",
    "    yp = y[2:N] # predicted\n",
    "    xp = x[2:N] # original\n",
    "    e = yp-xp # residuals\n",
    "\n",
    "    # stats on residuals\n",
    "    out['meane'] = np.mean(e)\n",
    "    out['meanabs'] = np.mean(np.abs(e))\n",
    "    out['rmse'] = np.sqrt(np.mean(e**2))\n",
    "    out['stde'] = np.std(e, ddof=1)\n",
    "    out['mms'] = np.abs(np.mean(e)) + np.abs(np.std(e, ddof=1))\n",
    "    out['maxonmean'] = np.max(e)/np.abs(np.mean(e))\n",
    "\n",
    "    if np.std(e, ddof=1) == 0:\n",
    "        e = np.zeros(len(e))\n",
    "    else:\n",
    "        e = BF_zscore(e)\n",
    "    \n",
    "    # Identify any low-frequency trends in residuals\n",
    "\n",
    "    # Analyze autocorrelation in residuals\n",
    "    maxLag = 25\n",
    "    autoCorrResid = CO_AutoCorr(e, list(np.arange(1, maxLag+1)), 'Fourier')\n",
    "    sqrtN = np.sqrt(N)\n",
    "    out['ac1'] = autoCorrResid[0]\n",
    "    out['ac2'] = autoCorrResid[1]\n",
    "    out['ac3'] = autoCorrResid[2]\n",
    "    out['ac1n'] = autoCorrResid[0]*sqrtN\n",
    "    out['ac2n'] = autoCorrResid[1]*sqrtN\n",
    "    out['ac3n'] = autoCorrResid[2]*sqrtN\n",
    "\n",
    "    # Median normalized distance from zero\n",
    "    out['acmnd0'] = np.median(np.abs(autoCorrResid))*sqrtN \n",
    "    out['acsnd0'] = np.std(np.abs(autoCorrResid), ddof=1)*sqrtN\n",
    "    out['propbth'] = np.sum(np.abs(autoCorrResid) < 2.6/sqrtN)/maxLag\n",
    "\n",
    "    # First time to get below the significance threshold\n",
    "    ftbth = np.argwhere(np.abs(autoCorrResid) < 2.6/sqrtN).flatten()[0]\n",
    "    if not ftbth:\n",
    "        ftbth = maxLag + 1\n",
    "    \n",
    "    out['ftbth'] = ftbth\n",
    "    #% Durbin-Watson test statistic (like AC1)\n",
    "    out['dwts'] = np.sum((e[1:] - e[:-1])**2) / np.sum(e**2)\n",
    "\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def SUB_fit_exp_smooth(x, a):\n",
    "    ntrain = len(x)\n",
    "    xf = np.zeros(ntrain)\n",
    "    \n",
    "    for i in range(1, ntrain - 1):\n",
    "        s = np.zeros(i + 1)\n",
    "        s[0] = np.mean(x[0:i])\n",
    "        \n",
    "        # Smooth data within the window\n",
    "        for j in range(1, i + 1):\n",
    "            s[j] = a * x[j] + (1 - a) * s[j - 1]\n",
    "        \n",
    "        #The forecast for x[i+1] is taken as the last smoothed value s[i]\n",
    "        xf[i + 1] = s[i]\n",
    "    \n",
    "    return xf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alphamin_1': np.float64(1.0901076386948796),\n",
       " 'p1_1': np.float64(0.3665076982852078),\n",
       " 'cup_1': np.float64(1.0),\n",
       " 'alphamin': 1,\n",
       " 'meane': np.float64(0.001265250501002004),\n",
       " 'meanabs': np.float64(0.1267746092184369),\n",
       " 'rmse': np.float64(0.14090634055511642),\n",
       " 'stde': np.float64(0.14097130446993963),\n",
       " 'mms': np.float64(0.14223655497094165),\n",
       " 'maxonmean': np.float64(157.8074854282818),\n",
       " 'ac1': np.float64(0.9789764444623205),\n",
       " 'ac2': np.float64(0.919003505565848),\n",
       " 'ac3': np.float64(0.8225485607199285),\n",
       " 'ac1n': np.float64(30.95795340154266),\n",
       " 'ac2n': np.float64(29.06144255267308),\n",
       " 'ac3n': np.float64(26.011269379682837),\n",
       " 'acmnd0': np.float64(20.24163306315739),\n",
       " 'acsnd0': np.float64(10.142573846880763),\n",
       " 'propbth': np.float64(0.04),\n",
       " 'ftbth': np.int64(7),\n",
       " 'dwts': np.float64(0.040146836050223816)}"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = MF_ExpSmoothing(ts1, 0.5)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04891096,  0.12065962,  0.03132307, -0.18413738, -0.23652705,\n",
       "       -0.36872942, -0.29583703, -0.1893701 , -0.11025447,  0.11082915,\n",
       "        0.20518548,  0.33283003,  0.33624639,  0.25478703,  0.11958142,\n",
       "       -0.08063441, -0.16793048, -0.28780988, -0.36458256, -0.24298984,\n",
       "       -0.1825511 ,  0.01683114,  0.15704877,  0.26346958,  0.31175132])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CO_AutoCorr(e, taus, 'Fourier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.004, 0.1  , 0.1  , 0.3  , 0.4  ])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort([0.1, 0.3, 0.4, 0.1, 0.004])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.   , 0.005, 0.01 , 0.015, 0.02 , 0.025, 0.03 , 0.035, 0.04 ,\n",
       "       0.045, 0.05 , 0.055, 0.06 , 0.065, 0.07 , 0.075, 0.08 , 0.085,\n",
       "       0.09 , 0.095, 0.1  , 0.105, 0.11 , 0.115, 0.12 , 0.125, 0.13 ,\n",
       "       0.135, 0.14 , 0.145, 0.15 , 0.155, 0.16 , 0.165, 0.17 , 0.175,\n",
       "       0.18 , 0.185, 0.19 , 0.195, 0.2  , 0.205, 0.21 , 0.215, 0.22 ,\n",
       "       0.225, 0.23 , 0.235, 0.24 , 0.245, 0.25 , 0.255, 0.26 , 0.265,\n",
       "       0.27 , 0.275, 0.28 , 0.285, 0.29 , 0.295, 0.3  , 0.305, 0.31 ,\n",
       "       0.315, 0.32 , 0.325, 0.33 , 0.335, 0.34 , 0.345, 0.35 , 0.355,\n",
       "       0.36 , 0.365, 0.37 , 0.375, 0.38 , 0.385, 0.39 , 0.395, 0.4  ,\n",
       "       0.405, 0.41 , 0.415, 0.42 , 0.425, 0.43 , 0.435, 0.44 , 0.445,\n",
       "       0.45 , 0.455, 0.46 , 0.465, 0.47 , 0.475, 0.48 , 0.485, 0.49 ,\n",
       "       0.495, 0.5  , 0.505, 0.51 , 0.515, 0.52 , 0.525, 0.53 , 0.535,\n",
       "       0.54 , 0.545, 0.55 , 0.555, 0.56 , 0.565, 0.57 , 0.575, 0.58 ,\n",
       "       0.585, 0.59 , 0.595, 0.6  , 0.605, 0.61 , 0.615, 0.62 , 0.625,\n",
       "       0.63 , 0.635, 0.64 , 0.645, 0.65 , 0.655, 0.66 , 0.665, 0.67 ,\n",
       "       0.675, 0.68 , 0.685, 0.69 , 0.695, 0.7  , 0.705, 0.71 , 0.715,\n",
       "       0.72 , 0.725, 0.73 , 0.735, 0.74 , 0.745, 0.75 , 0.755, 0.76 ,\n",
       "       0.765, 0.77 , 0.775, 0.78 , 0.785, 0.79 , 0.795, 0.8  , 0.805,\n",
       "       0.81 , 0.815, 0.82 , 0.825, 0.83 , 0.835, 0.84 , 0.845, 0.85 ,\n",
       "       0.855, 0.86 , 0.865, 0.87 , 0.875, 0.88 , 0.885, 0.89 , 0.895,\n",
       "       0.9  , 0.905, 0.91 , 0.915, 0.92 , 0.925, 0.93 , 0.935, 0.94 ,\n",
       "       0.945, 0.95 , 0.955, 0.96 , 0.965, 0.97 , 0.975, 0.98 , 0.985,\n",
       "       0.99 , 0.995, 1.   ])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aar = np.arange(0, 1.005, 0.005)\n",
    "aar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "GaussianModel.guess() missing 1 required positional argument: 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m gmodel \u001b[38;5;241m=\u001b[39m GaussianModel()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mgmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mguess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mts1\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: GaussianModel.guess() missing 1 required positional argument: 'x'"
     ]
    }
   ],
   "source": [
    "gmodel = GaussianModel()\n",
    "gmodel.guess(ts1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(-0.09999450000000012)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dny, binEdges = BF_SimpleBinner(ts1, 10)\n",
    "dnx = np.mean([binEdges[:-1]])\n",
    "dnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.8999905, -0.6999915, -0.4999925, -0.2999935, -0.0999945,\n",
       "        0.1000045,  0.3000035,  0.5000025,  0.7000015,  0.9000005])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = binEdges[:-1]\n",
    "b = binEdges[1:]\n",
    "stacked = np.vstack((a, b))\n",
    "np.mean(stacked, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-9.99990e-01, -7.99991e-01, -5.99992e-01, -3.99993e-01,\n",
       "       -1.99994e-01,  5.00000e-06,  2.00004e-01,  4.00003e-01,\n",
       "        6.00002e-01,  8.00001e-01, -5.99992e-01, -3.99993e-01,\n",
       "       -1.99994e-01,  5.00000e-06,  2.00004e-01,  4.00003e-01,\n",
       "        6.00002e-01,  8.00001e-01])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.hstack([binEdges[:-1], binEdges[2:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findMyThreshold(x, det_s, N):\n",
    "    pr = np.argwhere(det_s < x*np.max(det_s)).flatten()\n",
    "    if len(pr) == 0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return pr[0]/N\n",
    "\n",
    "def WL_coeffs(y : list, wname : str = 'db3', level : int = 3):\n",
    "    N = len(y)\n",
    "    if level == 'max':\n",
    "        level = pywt.dwt_max_level(N, wname)\n",
    "        if level == 0:\n",
    "            raise ValueError(\"Cannot compute wavelet coefficients (short time series)\")\n",
    "    \n",
    "    if pywt.dwt_max_level(N, wname) < level:\n",
    "        raise ValueError(f\"Chosen level, {level}, is too large for this wavelet on this signal.\")\n",
    "    \n",
    "    #coeffs = pywt.wavedec(y, wname, level=level)\n",
    "    C, L = wavedec(y, wavelet=wname, level=level)\n",
    "    det = wrcoef(C, L, wname, level)\n",
    "    det_s = np.sort(np.abs(det))[::-1]\n",
    "\n",
    "    #%% Return statistics\n",
    "    out = {}\n",
    "    out['mean_coeff'] = np.mean(det_s)\n",
    "    out['max_coeff'] = np.max(det_s)\n",
    "    out['med_coeff'] = np.median(det_s)\n",
    "\n",
    "    #% Decay rate stats ('where below _ maximum' = 'wb_m')\n",
    "    out['wb99m'] = findMyThreshold(0.99, det_s, N)\n",
    "    out['wb90m'] = findMyThreshold(0.90, det_s, N)\n",
    "    out['wb75m'] = findMyThreshold(0.75, det_s, N)\n",
    "    out['wb50m'] = findMyThreshold(0.50, det_s, N)\n",
    "    out['wb25m'] = findMyThreshold(0.25, det_s, N)\n",
    "    out['wb10m'] = findMyThreshold(0.10, det_s, N)\n",
    "    out['wb1m'] = findMyThreshold(0.01, det_s, N)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_coeff': np.float64(0.09842152327706816),\n",
       " 'max_coeff': np.float64(0.2954158069152821),\n",
       " 'med_coeff': np.float64(0.09023773051023212),\n",
       " 'wb99m': np.float64(0.002),\n",
       " 'wb90m': np.float64(0.002),\n",
       " 'wb75m': np.float64(0.044),\n",
       " 'wb50m': np.float64(0.223),\n",
       " 'wb25m': np.float64(0.585),\n",
       " 'wb10m': np.float64(0.845),\n",
       " 'wb1m': np.float64(0.983)}"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WL_coeffs(ts1, 'db3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SY_LocalDistributions(y : list, numSegs : int = 5, eachOrPar : str = 'par', numPoints : int = 200):\n",
    "    N = len(y)\n",
    "    lseg = np.floor(N/numSegs)\n",
    "    dns = np.zeros((numPoints, numSegs))\n",
    "    r = np.linspace(np.min(y), np.max(y), numPoints)\n",
    "    \n",
    "    for i in range(numSegs):\n",
    "        fit_to = y[int((i)*lseg+1):int((i+1)*lseg)]\n",
    "        kde = KernelDensity(bandwidth='silverman', kernel='gaussian').fit(fit_to[:, None])\n",
    "        dns[:, i] = np.exp(kde.score_samples(r[:, None]))\n",
    "\n",
    "    if eachOrPar in ['par', 'parent']:\n",
    "        #% Compares each subdistribtuion to the parent (full signal) distribution\n",
    "        kde = KernelDensity(bandwidth='silverman', kernel='gaussian').fit(y[:, None])\n",
    "        pardn = np.exp(kde.score_samples(r[:, None]))\n",
    "        divs = np.zeros(numSegs)\n",
    "        for i in range(numSegs):\n",
    "            divs[i] = np.sum(np.abs(dns[:, i]-pardn))\n",
    "\n",
    "    elif eachOrPar == 'each':\n",
    "        #% Compares each subdistribtuion to the parent (full signal) distribution\n",
    "        if numSegs == 2:\n",
    "            out = np.sum(np.abs(dns[:, 0]-dns[:, 1]))\n",
    "            return out\n",
    "        diffmat = np.nan * np.empty((numSegs, numSegs,))\n",
    "        for i in range(numSegs):\n",
    "            for j in range(numSegs):\n",
    "                diffmat[i, j] = np.sum(np.abs(dns[:, i]-dns[:,j]))\n",
    "    \n",
    "        divs = diffmat[np.triu_indices_from(diffmat, k=1)]\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method {eachOrPar} should be 'each' or 'par'\")\n",
    "\n",
    "    #% Return basic statistics on differences in distributions in different segments of the time series\n",
    "    out = {}\n",
    "    out['meandiv'] = np.mean(divs)\n",
    "    out['mediandiv'] = np.median(divs)\n",
    "    out['mindiv'] = np.min(divs)\n",
    "    out['maxdiv'] = np.max(divs)\n",
    "    out['stddiv'] = np.std(divs, ddof=1)\n",
    "    \n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meandiv': np.float64(9.533297079841278),\n",
       " 'mediandiv': np.float64(9.232399692106519),\n",
       " 'mindiv': np.float64(8.532618509422912),\n",
       " 'maxdiv': np.float64(11.237563242946587),\n",
       " 'stddiv': np.float64(0.993290702736522)}"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SY_LocalDistributions(ts1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NL_fnn(y, maxdim = 10, tau = 1, th = 5, kth = 1, justBest = 0, bestp = 0.1):\n",
    "    dim = np.arange(1, maxdim+1)\n",
    "    p = dimension.fnn(y, dim=dim, tau=tau, R=th, window=kth)[0]\n",
    "    if justBest:\n",
    "        out = dim[np.argwhere(p < bestp)[0]]\n",
    "    else:\n",
    "        out = {}\n",
    "        for i in range(maxdim):\n",
    "            out[f\"pfnn_{i+1}\"] = p[i]\n",
    "\n",
    "        out['meanpfnn'] = np.mean(p)\n",
    "        out['stdpfnn'] = np.std(p, ddof=1)\n",
    "\n",
    "        # find embedding dimension for the first time p goes under x%\n",
    "        out['firstunder02'] = dim[np.argwhere(p < 0.2)[0]][0]\n",
    "        out['firstunder01'] = dim[np.argwhere(p < 0.1)[0]][0]\n",
    "        out['firstunder005'] = dim[np.argwhere(p < 0.05)[0]][0]\n",
    "        out['firstunder002'] = dim[np.argwhere(p < 0.02)[0]][0]\n",
    "        out['firstunder001'] = dim[np.argwhere(p < 0.01)[0]][0]\n",
    "\n",
    "        out['max1stepchange'] = np.max(np.abs(np.diff(p)))\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.98498498, 0.78657315, 0.44032096, 0.15963855, 0.05226131,\n",
       "        0.01307847, 0.0020141 , 0.        , 0.        , 0.        ],\n",
       "       [0.16816817, 0.15531062, 0.16950853, 0.18072289, 0.19497487,\n",
       "        0.2444668 , 0.30110775, 0.36693548, 0.49243189, 0.61616162],\n",
       "       [0.98498498, 0.78757515, 0.45235707, 0.23694779, 0.20301508,\n",
       "        0.24647887, 0.30110775, 0.36693548, 0.49243189, 0.61616162]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimension.fnn(ts3, dim=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], tau=1, R=5,window=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DN_OutlierInclude(y, thresholdHow : str = 'abs', inc : float = 0.01):\n",
    "    #% If the time series is a constant causes issues\n",
    "    if np.all(y[1] == y):\n",
    "        # % This method is not suitable for such time series: return a NaN\n",
    "        warnings.warn(\"The time series is a constant!\")\n",
    "        return np.nan\n",
    "    \n",
    "    # % Check z-scored time series\n",
    "    if not BF_iszscored(y):\n",
    "        warnings.warn(\"The input time series should be z-scored\")\n",
    "    N = len(y)\n",
    "    \n",
    "    #%% Initialize thresholds\n",
    "    # % ------------------------------------------------------------------------------\n",
    "    # % Could be better to just use a fixed number of increments here, from 0 to the max.\n",
    "    # % (rather than forcing a fixed inc)\n",
    "    if thresholdHow == 'abs': # % analyze absolute value deviations\n",
    "        thr = np.arange(0, max(abs(y)), inc)\n",
    "        tot = N\n",
    "    elif thresholdHow == 'pos':\n",
    "        thr = np.arange(0, max(y), inc)\n",
    "        tot = sum(y >= 0)\n",
    "    elif thresholdHow == 'neg':\n",
    "        thr = np.arange(0, max(-y), inc)\n",
    "        tot = sum(y <= 0)\n",
    "    else:\n",
    "        raise ValueError(f\"Error thresholding with '{thresholdHow}'. Must select either 'abs', 'pos', or 'neg'.\")\n",
    "    \n",
    "    if len(thr) == 0:\n",
    "        raise ValueError(\"Error setting increments through the time-series values...\")\n",
    "    \n",
    "    msDt = np.zeros((len(thr), 6))\n",
    "\n",
    "    # % Calculate statistics of over-threshold events, looping over thresholds\n",
    "    for (i, th) in enumerate(thr):\n",
    "        if thresholdHow == 'abs':\n",
    "            r = np.argwhere(abs(y >= th)).flatten()\n",
    "        elif thresholdHow == 'pos':\n",
    "            r = np.argwhere(y >= th).flatten()\n",
    "        elif thresholdHow == 'neg':\n",
    "            r = np.argwhere(y <= -th).flatten()\n",
    "        \n",
    "        Dt_exc = np.diff(r)\n",
    "        msDt[i, 0] = np.mean(Dt_exc)\n",
    "        msDt[i, 1] = np.std(Dt_exc, ddof=1)/np.sqrt(len(r))\n",
    "        msDt[i, 2] = len(Dt_exc)/tot*100\n",
    "        msDt[i, 3] = (np.median(r)/(N/2)) - 1\n",
    "        msDt[i, 4] = np.mean(r)/(N/2) - 1\n",
    "        msDt[i, 5] = np.std(r, ddof=1)/np.sqrt(len(r))\n",
    "\n",
    "    #%% Trim\n",
    "    fbi = np.argmax(np.isnan(msDt[:, 0])) if np.any(np.isnan(msDt[:, 0])) else None\n",
    "    if fbi:\n",
    "        msDt = msDt[:fbi, :]\n",
    "        thr = thr[:fbi]\n",
    "    trimthr = 2 \n",
    "    mj_indices = np.where(msDt[:, 2] > trimthr)[0]\n",
    "    if mj_indices.size > 0:\n",
    "        mj = mj_indices[-1]  # last index\n",
    "        # In MATLAB: msDt = msDt(1:mj,:); we slice up to mj+1 in Python\n",
    "        msDt = msDt[:mj+1, :]\n",
    "        thr = thr[:mj+1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return fbi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "msDt = np.array([\n",
    "    [4, 5],\n",
    "    [5, 6]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "fbi = np.argmax(np.isnan(msDt[:, 0])) if np.any(np.isnan(msDt[:, 0])) else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty\n"
     ]
    }
   ],
   "source": [
    "if not fbi:\n",
    "    print(\"empty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pt/9v0934pn6s1g4klqjbcz65p40000gp/T/ipykernel_50058/3526833644.py:10: UserWarning: The input time series should be z-scored\n",
      "  warnings.warn(\"The input time series should be z-scored\")\n"
     ]
    }
   ],
   "source": [
    "msDt = DN_OutlierInclude(ts1, 'neg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.98787879e+00,  1.71847328e-01,  9.95975855e+01, -1.00000000e-03,\n",
       "        1.06854839e-02,  1.29149570e+01])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msDt[1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.0395880299049998)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DN_pleft(ts4, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DN_CompareKSFit(x : list, whatDistn : str = 'norm') -> dict:\n",
    "\n",
    "    # Fit the distribution 'whatDistn' to the input data, x.\n",
    "    xStep = np.std(x, ddof=1)/100 # set a step size\n",
    "    if whatDistn == 'norm':\n",
    "        (a, b) = stats.norm.fit(x)\n",
    "        peaky = stats.norm.pdf(a, a, b)\n",
    "        thresh = peaky/100\n",
    "        xf1 = np.mean(x)\n",
    "        ange = 10\n",
    "        while ange > thresh:\n",
    "            xf1 = xf1 - xStep\n",
    "            ange = stats.norm.pdf(xf1, a, b)\n",
    "        xf2 = np.mean(x)\n",
    "        ange = 10\n",
    "        while ange > thresh:\n",
    "            xf2 = xf2 + xStep\n",
    "            ange = stats.norm.pdf(xf2, a, b)\n",
    "        xf = [xf1, xf2]\n",
    "\n",
    "    # Estimate smoothed empirical distribution\n",
    "    kde = KernelDensity(bandwidth='silverman', kernel='gaussian').fit(x[:, None]) # closest match to the default behaviour of ksdensity in MATLAB\n",
    "    lower = x.min() - 3 * kde.bandwidth_\n",
    "    upper = x.max() + 3 * kde.bandwidth_\n",
    "    xi = np.linspace(lower, upper, 100)[:,None]\n",
    "    f = np.exp(kde.score_samples(xi))\n",
    "    xi = xi[f > 1E-6]\n",
    "    if len(xi) == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    xi = [np.floor(xi[0]*10)/10, np.ceil(xi[-1]*10)/10]\n",
    "\n",
    "    # Find appropriate range [x1 x2] that incorporates the full range of both\n",
    "    x1 = min(xf[0], xi[0])\n",
    "    x2 = max(xf[1], xi[1])\n",
    "\n",
    "    xi = np.linspace(x1, x2, 1000)[:, None]\n",
    "    kde = KernelDensity(bandwidth='silverman', kernel='gaussian').fit(x[:, None])\n",
    "    f = np.exp(kde.score_samples(xi))\n",
    "    ffit = stats.norm.pdf(xi, a, b)\n",
    "\n",
    "    adiff = np.sum(abs(f - ffit)*(xi[1] - xi[0]))\n",
    "    max1 = np.max(f)\n",
    "    max2 = np.max(ffit)\n",
    "    peaksepy = max2-max1\n",
    "\n",
    "    i1 = np.argmax(f)\n",
    "    i2 = np.argmax(ffit)\n",
    "    peaksepx = xi[i2] - xi[i1]\n",
    "\n",
    "    olapint = sum(sum(f * ffit) * (xi[1] - xi[0])) * np.std(x, ddof=1)\n",
    "\n",
    "\n",
    "    return peaksepy, peaksepx, olapint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.08766587476060284),\n",
       " array([-0.77181288]),\n",
       " np.float64(163.92612892310967))"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DN_CompareKSFit(ts1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde = KernelDensity(bandwidth='silverman', kernel='gaussian').fit(ts1[:, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower = ts1.min() - 3 * kde.bandwidth_\n",
    "upper = ts1.max() + 3 * kde.bandwidth_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00193995, 0.00295549, 0.00442302, 0.00650255, 0.00939184,\n",
       "       0.01332756, 0.01858304, 0.02546165, 0.0342848 , 0.04537408,\n",
       "       0.05902781, 0.07549287, 0.09493363, 0.11740099, 0.14280473,\n",
       "       0.17089318, 0.20124363, 0.23326654, 0.26622495, 0.299269  ,\n",
       "       0.33148362, 0.36194524, 0.38978253, 0.4142349 , 0.43470273,\n",
       "       0.45078434, 0.46229597, 0.46927332, 0.4719554 , 0.47075333,\n",
       "       0.46620836, 0.45894416, 0.44961864, 0.43887982, 0.42732933,\n",
       "       0.41549575, 0.40381836, 0.39264091, 0.38221389, 0.37270314,\n",
       "       0.36420264, 0.3567493 , 0.3503379 , 0.34493494, 0.34049053,\n",
       "       0.33694795, 0.33425095, 0.3323489 , 0.33120029, 0.33077496,\n",
       "       0.33105539, 0.33203736, 0.33373009, 0.3361559 , 0.33934909,\n",
       "       0.34335395, 0.34822135, 0.35400356, 0.36074694, 0.36848229,\n",
       "       0.37721285, 0.38690031, 0.39744982, 0.40869516, 0.42038603,\n",
       "       0.43217949, 0.44363783, 0.45423501, 0.46337295, 0.47040832,\n",
       "       0.47468902, 0.47559819, 0.47260222, 0.46529811, 0.45345511,\n",
       "       0.43704553, 0.41626048, 0.39150801, 0.36339287, 0.33267936,\n",
       "       0.30024109, 0.26700248, 0.23387827, 0.20171686, 0.17125305,\n",
       "       0.14307368, 0.11759845, 0.09507602, 0.07559368, 0.05909787,\n",
       "       0.04542184, 0.03431674, 0.02548259, 0.01859648, 0.01333601,\n",
       "       0.00939704, 0.00650568, 0.00442486, 0.00295654, 0.00194054])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(kde.score_samples(np.linspace(lower, upper, 100)[:,None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyhctsa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
